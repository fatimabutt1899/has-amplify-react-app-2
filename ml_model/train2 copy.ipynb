{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__typename</th>\n",
       "      <th>deviceID</th>\n",
       "      <th>userID</th>\n",
       "      <th>updatedAt</th>\n",
       "      <th>eventStatus</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>createdAt</th>\n",
       "      <th>owner</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeviceTimeStamp</td>\n",
       "      <td>6y2e0q34-992e-901d-2r24-4t99e27q9789</td>\n",
       "      <td>aye06b84-ceb1-4f65-8407-13cd12663818</td>\n",
       "      <td>2023-11-14T05:00:00.001Z</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-11-14 05:00:00.001</td>\n",
       "      <td>2023-11-14T05:00:00.001Z</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...</td>\n",
       "      <td>jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2b61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DeviceTimeStamp</td>\n",
       "      <td>111j6h66-938q-278r-8e24-4t99e27q8371</td>\n",
       "      <td>fat06b84-ceb1-4f65-8407-13cd12663818</td>\n",
       "      <td>2023-12-01T23:17:00.001Z</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-12-01 23:17:00.001</td>\n",
       "      <td>2023-12-01T23:17:00.001Z</td>\n",
       "      <td>fat06b84-ceb1-4f65-8407-13cd12663818::fat06b84...</td>\n",
       "      <td>jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2j67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DeviceTimeStamp</td>\n",
       "      <td>7a2e3c32-888a-446c-9d15-8f79f40a7331</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818</td>\n",
       "      <td>2023-12-05T14:00:00.001Z</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-12-05 14:00:00.001</td>\n",
       "      <td>2023-12-05T14:00:00.001Z</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...</td>\n",
       "      <td>jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2j86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeviceTimeStamp</td>\n",
       "      <td>6y2e0q34-992e-901d-2r24-4t99e27q9789</td>\n",
       "      <td>aye06b84-ceb1-4f65-8407-13cd12663818</td>\n",
       "      <td>2023-11-22T14:30:00.001Z</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-22 14:30:00.001</td>\n",
       "      <td>2023-11-22T14:30:00.001Z</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...</td>\n",
       "      <td>jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2f65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DeviceTimeStamp</td>\n",
       "      <td>ab4454c7-1d75-4328-af9c-f03a12ccea2b</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818</td>\n",
       "      <td>2023-10-27T21:00:00.001Z</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-10-27 21:00:00.001</td>\n",
       "      <td>2023-10-27T21:00:00.001Z</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...</td>\n",
       "      <td>jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2c08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>DeviceTimeStamp</td>\n",
       "      <td>9c1j6h66-938q-278r-8e24-4t99e27q8371</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818</td>\n",
       "      <td>2023-11-02T08:33:00.001Z</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-11-02 08:33:00.001</td>\n",
       "      <td>2023-11-02T08:33:00.001Z</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...</td>\n",
       "      <td>hij6d759-1240-4d42-ab68-827b9bf22acd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>DeviceTimeStamp</td>\n",
       "      <td>6y2e0q34-992e-901d-2r24-4t99e27q9789</td>\n",
       "      <td>aye06b84-ceb1-4f65-8407-13cd12663818</td>\n",
       "      <td>2023-11-18T14:00:00.001Z</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-18 14:00:00.001</td>\n",
       "      <td>2023-11-18T14:00:00.001Z</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...</td>\n",
       "      <td>jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2d38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>DeviceTimeStamp</td>\n",
       "      <td>9c1j6h66-938q-278r-8e24-4t99e27q8371</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818</td>\n",
       "      <td>2023-11-24T06:00:00.001Z</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-11-24 06:00:00.001</td>\n",
       "      <td>2023-11-24T06:00:00.001Z</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...</td>\n",
       "      <td>jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2h39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>DeviceTimeStamp</td>\n",
       "      <td>ab4454c7-1d75-4328-af9c-f03a12ccea2b</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818</td>\n",
       "      <td>2023-12-04T08:30:00.001Z</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-12-04 08:30:00.001</td>\n",
       "      <td>2023-12-04T08:30:00.001Z</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...</td>\n",
       "      <td>jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2j38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>DeviceTimeStamp</td>\n",
       "      <td>7a2e3c32-888a-446c-9d15-8f79f40a7331</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818</td>\n",
       "      <td>2023-11-25T20:00:00.001Z</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-11-25 20:00:00.001</td>\n",
       "      <td>2023-11-25T20:00:00.001Z</td>\n",
       "      <td>b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...</td>\n",
       "      <td>jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2f62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          __typename                              deviceID  \\\n",
       "0    DeviceTimeStamp  6y2e0q34-992e-901d-2r24-4t99e27q9789   \n",
       "1    DeviceTimeStamp  111j6h66-938q-278r-8e24-4t99e27q8371   \n",
       "2    DeviceTimeStamp  7a2e3c32-888a-446c-9d15-8f79f40a7331   \n",
       "3    DeviceTimeStamp  6y2e0q34-992e-901d-2r24-4t99e27q9789   \n",
       "4    DeviceTimeStamp  ab4454c7-1d75-4328-af9c-f03a12ccea2b   \n",
       "..               ...                                   ...   \n",
       "955  DeviceTimeStamp  9c1j6h66-938q-278r-8e24-4t99e27q8371   \n",
       "956  DeviceTimeStamp  6y2e0q34-992e-901d-2r24-4t99e27q9789   \n",
       "957  DeviceTimeStamp  9c1j6h66-938q-278r-8e24-4t99e27q8371   \n",
       "958  DeviceTimeStamp  ab4454c7-1d75-4328-af9c-f03a12ccea2b   \n",
       "959  DeviceTimeStamp  7a2e3c32-888a-446c-9d15-8f79f40a7331   \n",
       "\n",
       "                                   userID                 updatedAt  \\\n",
       "0    aye06b84-ceb1-4f65-8407-13cd12663818  2023-11-14T05:00:00.001Z   \n",
       "1    fat06b84-ceb1-4f65-8407-13cd12663818  2023-12-01T23:17:00.001Z   \n",
       "2    b3f06b84-ceb1-4f65-8407-13cd12663818  2023-12-05T14:00:00.001Z   \n",
       "3    aye06b84-ceb1-4f65-8407-13cd12663818  2023-11-22T14:30:00.001Z   \n",
       "4    b3f06b84-ceb1-4f65-8407-13cd12663818  2023-10-27T21:00:00.001Z   \n",
       "..                                    ...                       ...   \n",
       "955  b3f06b84-ceb1-4f65-8407-13cd12663818  2023-11-02T08:33:00.001Z   \n",
       "956  aye06b84-ceb1-4f65-8407-13cd12663818  2023-11-18T14:00:00.001Z   \n",
       "957  b3f06b84-ceb1-4f65-8407-13cd12663818  2023-11-24T06:00:00.001Z   \n",
       "958  b3f06b84-ceb1-4f65-8407-13cd12663818  2023-12-04T08:30:00.001Z   \n",
       "959  b3f06b84-ceb1-4f65-8407-13cd12663818  2023-11-25T20:00:00.001Z   \n",
       "\n",
       "     eventStatus               timestamp                 createdAt  \\\n",
       "0          False 2023-11-14 05:00:00.001  2023-11-14T05:00:00.001Z   \n",
       "1           True 2023-12-01 23:17:00.001  2023-12-01T23:17:00.001Z   \n",
       "2           True 2023-12-05 14:00:00.001  2023-12-05T14:00:00.001Z   \n",
       "3           True 2023-11-22 14:30:00.001  2023-11-22T14:30:00.001Z   \n",
       "4          False 2023-10-27 21:00:00.001  2023-10-27T21:00:00.001Z   \n",
       "..           ...                     ...                       ...   \n",
       "955        False 2023-11-02 08:33:00.001  2023-11-02T08:33:00.001Z   \n",
       "956         True 2023-11-18 14:00:00.001  2023-11-18T14:00:00.001Z   \n",
       "957        False 2023-11-24 06:00:00.001  2023-11-24T06:00:00.001Z   \n",
       "958        False 2023-12-04 08:30:00.001  2023-12-04T08:30:00.001Z   \n",
       "959         True 2023-11-25 20:00:00.001  2023-11-25T20:00:00.001Z   \n",
       "\n",
       "                                                 owner  \\\n",
       "0    b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
       "1    fat06b84-ceb1-4f65-8407-13cd12663818::fat06b84...   \n",
       "2    b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
       "3    b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
       "4    b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
       "..                                                 ...   \n",
       "955  b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
       "956  b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
       "957  b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
       "958  b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
       "959  b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
       "\n",
       "                                       id  \n",
       "0    jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2b61  \n",
       "1    jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2j67  \n",
       "2    jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2j86  \n",
       "3    jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2f65  \n",
       "4    jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2c08  \n",
       "..                                    ...  \n",
       "955  hij6d759-1240-4d42-ab68-827b9bf22acd  \n",
       "956  jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2d38  \n",
       "957  jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2h39  \n",
       "958  jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2j38  \n",
       "959  jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2f62  \n",
       "\n",
       "[960 rows x 9 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify your DynamoDB table details\n",
    "table_name = 'DeviceTimeStamp-zvvc26kofnethfd47fmdbb2skm-dev'\n",
    "\n",
    "# Create a DynamoDB client\n",
    "dynamodb = boto3.client('dynamodb')\n",
    "# Scan the DynamoDB table to retrieve all data\n",
    "\n",
    "response = dynamodb.scan(TableName=table_name)\n",
    "items = response['Items']\n",
    "\n",
    "# Convert DynamoDB items to a Pandas DataFrame\n",
    "df = pd.DataFrame(items)\n",
    "\n",
    "# Function to convert DynamoDB item to a dictionary of values\n",
    "def parse_dynamodb_item(item):\n",
    "    return {key: list(value.values())[0] for key, value in item.items()} \n",
    "\n",
    "# Apply the parsing function to each row in the DataFrame\n",
    "df = df.apply(parse_dynamodb_item, axis=1).apply(pd.Series)  # Convert Series to DataFrame\n",
    "\n",
    "# Convert timestamp strings to datetime objects if the 'timestamp' column exists\n",
    "if 'timestamp' in df.columns:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# Print the cleaned DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " __typename     0\n",
      "deviceID       0\n",
      "userID         0\n",
      "updatedAt      0\n",
      "eventStatus    0\n",
      "timestamp      0\n",
      "createdAt      0\n",
      "owner          0\n",
      "id             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the DataFrame\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n",
    "\n",
    "# Handle missing values (if any) - for example, drop rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        __typename  deviceID  userID                 updatedAt  eventStatus  \\\n",
      "0  DeviceTimeStamp         1       0  2023-11-14T05:00:00.001Z        False   \n",
      "1  DeviceTimeStamp         0       2  2023-12-01T23:17:00.001Z         True   \n",
      "2  DeviceTimeStamp         2       1  2023-12-05T14:00:00.001Z         True   \n",
      "3  DeviceTimeStamp         1       0  2023-11-22T14:30:00.001Z         True   \n",
      "4  DeviceTimeStamp         4       1  2023-10-27T21:00:00.001Z        False   \n",
      "\n",
      "                timestamp                 createdAt  \\\n",
      "0 2023-11-14 05:00:00.001  2023-11-14T05:00:00.001Z   \n",
      "1 2023-12-01 23:17:00.001  2023-12-01T23:17:00.001Z   \n",
      "2 2023-12-05 14:00:00.001  2023-12-05T14:00:00.001Z   \n",
      "3 2023-11-22 14:30:00.001  2023-11-22T14:30:00.001Z   \n",
      "4 2023-10-27 21:00:00.001  2023-10-27T21:00:00.001Z   \n",
      "\n",
      "                                               owner  \\\n",
      "0  b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
      "1  fat06b84-ceb1-4f65-8407-13cd12663818::fat06b84...   \n",
      "2  b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
      "3  b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
      "4  b3f06b84-ceb1-4f65-8407-13cd12663818::b3f06b84...   \n",
      "\n",
      "                                     id  \n",
      "0  jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2b61  \n",
      "1  jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2j67  \n",
      "2  jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2j86  \n",
      "3  jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2f65  \n",
      "4  jkl4b9d8-dbf4-44fa-b3f8-c01dd3ce2c08  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Specify columns to be label encoded\n",
    "columns_to_encode = ['userID', 'deviceID']\n",
    "\n",
    "# Apply label encoding to the specified columns\n",
    "for column in columns_to_encode:\n",
    "    # Check if the column exists in the DataFrame and has dtype 'object'\n",
    "    if column in df.columns and df[column].dtype == 'object':\n",
    "        # Fit and transform the column with label encoding\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Display the DataFrame after label encoding\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Records (Selected Columns):\n",
      "     userID  deviceID  eventStatus               timestamp\n",
      "1         2         0         True 2023-12-01 23:17:00.001\n",
      "2         1         2         True 2023-12-05 14:00:00.001\n",
      "3         0         1         True 2023-11-22 14:30:00.001\n",
      "6         1         4         True 2023-11-28 05:00:00.001\n",
      "10        1         4         True 2023-10-27 14:01:00.001\n",
      "..      ...       ...          ...                     ...\n",
      "949       1         4         True 2023-11-07 14:00:00.001\n",
      "951       2         0         True 2023-11-26 23:01:00.001\n",
      "954       0         1         True 2023-11-24 20:00:00.001\n",
      "956       0         1         True 2023-11-18 14:00:00.001\n",
      "959       1         2         True 2023-11-25 20:00:00.001\n",
      "\n",
      "[480 rows x 4 columns]\n",
      "\n",
      "False Records (Selected Columns):\n",
      "     userID  deviceID  eventStatus               timestamp\n",
      "0         0         1        False 2023-11-14 05:00:00.001\n",
      "4         1         4        False 2023-10-27 21:00:00.001\n",
      "5         2         0        False 2023-11-14 07:00:00.001\n",
      "7         1         5        False 2023-11-29 14:00:00.001\n",
      "8         1         4        False 2023-11-21 06:00:00.001\n",
      "..      ...       ...          ...                     ...\n",
      "952       1         5        False 2023-11-15 22:00:00.001\n",
      "953       1         4        False 2023-11-06 21:00:00.001\n",
      "955       1         3        False 2023-11-02 08:33:00.001\n",
      "957       1         3        False 2023-11-24 06:00:00.001\n",
      "958       1         4        False 2023-12-04 08:30:00.001\n",
      "\n",
      "[480 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Specify columns to keep\n",
    "selected_columns = ['userID', 'deviceID', 'eventStatus', 'timestamp']\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "# Separate records into 'true' and 'false' using df_selected\n",
    "df_true_selected = df_selected[df_selected['eventStatus'] == True]\n",
    "df_false_selected = df_selected[df_selected['eventStatus'] == False]\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"True Records (Selected Columns):\")\n",
    "print(df_true_selected)\n",
    "\n",
    "print(\"\\nFalse Records (Selected Columns):\")\n",
    "print(df_false_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Records (Selected Columns - Sorted by Timestamp):\n",
      "     userID  deviceID  eventStatus               timestamp\n",
      "124       2         0         True 2023-12-30 23:30:00.001\n",
      "126       1         2         True 2023-12-30 23:10:00.001\n",
      "710       1         2         True 2023-12-30 20:10:00.001\n",
      "367       1         4         True 2023-12-07 05:00:00.001\n",
      "598       1         4         True 2023-12-06 14:00:00.001\n",
      "..      ...       ...          ...                     ...\n",
      "504       1         4         True 2023-10-21 07:12:00.001\n",
      "677       1         4         True 2023-10-21 05:04:00.001\n",
      "188       1         4         True 2023-10-20 14:01:00.001\n",
      "133       1         4         True 2023-10-20 07:03:00.001\n",
      "240       1         4         True 2023-10-20 05:10:00.001\n",
      "\n",
      "[480 rows x 4 columns]\n",
      "\n",
      "False Records (Selected Columns - Sorted by Timestamp):\n",
      "     userID  deviceID  eventStatus               timestamp\n",
      "567       1         2        False 2023-12-30 22:00:00.001\n",
      "721       0         1        False 2023-12-29 22:10:00.001\n",
      "889       1         4        False 2023-12-07 06:00:00.001\n",
      "816       1         4        False 2023-12-06 21:00:00.001\n",
      "345       1         4        False 2023-12-06 08:30:00.001\n",
      "..      ...       ...          ...                     ...\n",
      "629       1         4        False 2023-10-21 08:29:00.001\n",
      "616       1         4        False 2023-10-21 06:01:00.001\n",
      "899       1         4        False 2023-10-20 21:20:00.001\n",
      "132       1         4        False 2023-10-20 08:32:00.001\n",
      "372       1         4        False 2023-10-20 06:00:00.001\n",
      "\n",
      "[480 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sort 'true' records by timestamp in descending order\n",
    "df_true_selected = df_true_selected.sort_values(by='timestamp', ascending=False)\n",
    "\n",
    "# Sort 'false' records by timestamp in descending order\n",
    "df_false_selected = df_false_selected.sort_values(by='timestamp', ascending=False)\n",
    "\n",
    "# Display the sorted DataFrames\n",
    "print(\"True Records (Selected Columns - Sorted by Timestamp):\")\n",
    "print(df_true_selected)\n",
    "\n",
    "print(\"\\nFalse Records (Selected Columns - Sorted by Timestamp):\")\n",
    "print(df_false_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest 10 True Records (Selected Columns - Sorted by Timestamp - with Hours and Minutes):\n",
      "    userID  deviceID  eventStatus               timestamp  hours  minutes\n",
      "0        0         1         True 2023-11-29 20:00:00.001     20        0\n",
      "1        0         1         True 2023-11-29 14:00:00.001     14        0\n",
      "2        0         1         True 2023-11-28 23:00:00.001     23        0\n",
      "3        0         1         True 2023-11-28 20:00:00.001     20        0\n",
      "4        0         1         True 2023-11-28 14:00:00.001     14        0\n",
      "5        0         1         True 2023-11-27 23:00:00.001     23        0\n",
      "6        0         1         True 2023-11-27 20:00:00.001     20        0\n",
      "7        0         1         True 2023-11-27 14:00:00.001     14        0\n",
      "8        0         1         True 2023-11-26 23:00:00.001     23        0\n",
      "9        0         1         True 2023-11-26 20:00:00.001     20        0\n",
      "10       1         2         True 2023-12-30 23:10:00.001     23       10\n",
      "11       1         2         True 2023-12-30 20:10:00.001     20       10\n",
      "12       1         2         True 2023-12-05 14:00:00.001     14        0\n",
      "13       1         2         True 2023-12-04 23:00:00.001     23        0\n",
      "14       1         2         True 2023-12-04 20:07:00.001     20        7\n",
      "15       1         2         True 2023-12-04 14:00:00.001     14        0\n",
      "16       1         2         True 2023-12-03 23:00:00.001     23        0\n",
      "17       1         2         True 2023-12-03 20:10:00.001     20       10\n",
      "18       1         2         True 2023-12-03 14:00:00.001     14        0\n",
      "19       1         2         True 2023-12-02 23:00:00.001     23        0\n",
      "20       1         3         True 2023-12-05 05:00:00.001      5        0\n",
      "21       1         3         True 2023-12-04 14:00:00.001     14        0\n",
      "22       1         3         True 2023-12-04 07:00:00.001      7        0\n",
      "23       1         3         True 2023-12-04 05:00:00.001      5        0\n",
      "24       1         3         True 2023-12-03 14:00:00.001     14        0\n",
      "25       1         3         True 2023-12-03 07:00:00.001      7        0\n",
      "26       1         3         True 2023-12-03 05:00:00.001      5        0\n",
      "27       1         3         True 2023-12-02 14:00:00.001     14        0\n",
      "28       1         3         True 2023-12-02 07:00:00.001      7        0\n",
      "29       1         3         True 2023-12-02 05:00:00.001      5        0\n",
      "30       1         4         True 2023-12-07 05:00:00.001      5        0\n",
      "31       1         4         True 2023-12-06 14:00:00.001     14        0\n",
      "32       1         4         True 2023-12-06 07:00:00.001      7        0\n",
      "33       1         4         True 2023-12-06 05:00:00.001      5        0\n",
      "34       1         4         True 2023-12-05 14:00:00.001     14        0\n",
      "35       1         4         True 2023-12-05 07:00:00.001      7        0\n",
      "36       1         4         True 2023-12-05 05:00:00.001      5        0\n",
      "37       1         4         True 2023-12-04 14:00:00.001     14        0\n",
      "38       1         4         True 2023-12-04 07:00:00.001      7        0\n",
      "39       1         4         True 2023-12-04 05:00:00.001      5        0\n",
      "40       1         5         True 2023-11-29 23:00:00.001     23        0\n",
      "41       1         5         True 2023-11-29 18:01:00.001     18        1\n",
      "42       1         5         True 2023-11-29 07:00:00.001      7        0\n",
      "43       1         5         True 2023-11-28 23:00:00.001     23        0\n",
      "44       1         5         True 2023-11-28 07:03:00.001      7        3\n",
      "45       1         5         True 2023-11-27 23:00:00.001     23        0\n",
      "46       1         5         True 2023-11-27 18:00:00.001     18        0\n",
      "47       1         5         True 2023-11-27 18:00:00.001     18        0\n",
      "48       1         5         True 2023-11-27 07:02:00.001      7        2\n",
      "49       1         5         True 2023-11-26 23:00:00.001     23        0\n",
      "50       2         0         True 2023-12-30 23:30:00.001     23       30\n",
      "51       2         0         True 2023-12-02 15:00:00.001     15        0\n",
      "52       2         0         True 2023-12-01 23:17:00.001     23       17\n",
      "53       2         0         True 2023-12-01 15:00:00.001     15        0\n",
      "54       2         0         True 2023-11-30 15:00:00.001     15        0\n",
      "55       2         0         True 2023-11-29 23:05:00.001     23        5\n",
      "56       2         0         True 2023-11-29 15:02:00.001     15        2\n",
      "57       2         0         True 2023-11-28 23:01:00.001     23        1\n",
      "58       2         0         True 2023-11-28 15:02:00.001     15        2\n",
      "59       2         0         True 2023-11-27 23:00:00.001     23        0\n",
      "\n",
      "Latest 10 False Records (Selected Columns - Sorted by Timestamp - with Hours and Minutes):\n",
      "    userID  deviceID  eventStatus               timestamp  hours  minutes\n",
      "0        0         1        False 2023-12-29 22:10:00.001     22       10\n",
      "1        0         1        False 2023-11-29 17:00:00.001     17        0\n",
      "2        0         1        False 2023-11-29 05:00:00.001      5        0\n",
      "3        0         1        False 2023-11-28 22:10:00.001     22       10\n",
      "4        0         1        False 2023-11-28 17:00:00.001     17        0\n",
      "5        0         1        False 2023-11-28 05:10:00.001      5       10\n",
      "6        0         1        False 2023-11-27 22:00:00.001     22        0\n",
      "7        0         1        False 2023-11-27 17:00:00.001     17        0\n",
      "8        0         1        False 2023-11-27 05:00:00.001      5        0\n",
      "9        0         1        False 2023-11-26 22:00:00.001     22        0\n",
      "10       1         2        False 2023-12-30 22:00:00.001     22        0\n",
      "11       1         2        False 2023-12-05 17:00:00.001     17        0\n",
      "12       1         2        False 2023-12-05 05:00:00.001      5        0\n",
      "13       1         2        False 2023-12-04 22:00:00.001     22        0\n",
      "14       1         2        False 2023-12-04 17:00:00.001     17        0\n",
      "15       1         2        False 2023-12-04 05:00:00.001      5        0\n",
      "16       1         2        False 2023-12-03 22:00:00.001     22        0\n",
      "17       1         2        False 2023-12-03 17:00:00.001     17        0\n",
      "18       1         2        False 2023-12-03 05:00:00.001      5        0\n",
      "19       1         2        False 2023-12-02 22:00:00.001     22        0\n",
      "20       1         3        False 2023-12-05 06:00:00.001      6        0\n",
      "21       1         3        False 2023-12-04 21:00:00.001     21        0\n",
      "22       1         3        False 2023-12-04 08:30:00.001      8       30\n",
      "23       1         3        False 2023-12-04 06:00:00.001      6        0\n",
      "24       1         3        False 2023-12-03 21:00:00.001     21        0\n",
      "25       1         3        False 2023-12-03 08:30:00.001      8       30\n",
      "26       1         3        False 2023-12-03 06:00:00.001      6        0\n",
      "27       1         3        False 2023-12-02 21:00:00.001     21        0\n",
      "28       1         3        False 2023-12-02 08:30:00.001      8       30\n",
      "29       1         3        False 2023-12-02 06:00:00.001      6        0\n",
      "30       1         4        False 2023-12-07 06:00:00.001      6        0\n",
      "31       1         4        False 2023-12-06 21:00:00.001     21        0\n",
      "32       1         4        False 2023-12-06 08:30:00.001      8       30\n",
      "33       1         4        False 2023-12-06 06:00:00.001      6        0\n",
      "34       1         4        False 2023-12-05 21:00:00.001     21        0\n",
      "35       1         4        False 2023-12-05 08:30:00.001      8       30\n",
      "36       1         4        False 2023-12-05 06:00:00.001      6        0\n",
      "37       1         4        False 2023-12-04 21:00:00.001     21        0\n",
      "38       1         4        False 2023-12-04 08:30:00.001      8       30\n",
      "39       1         4        False 2023-12-04 06:00:00.001      6        0\n",
      "40       1         5        False 2023-11-30 05:00:00.001      5        0\n",
      "41       1         5        False 2023-11-29 14:00:00.001     14        0\n",
      "42       1         5        False 2023-11-29 05:00:00.001      5        0\n",
      "43       1         5        False 2023-11-28 22:01:00.001     22        1\n",
      "44       1         5        False 2023-11-28 22:00:00.001     22        0\n",
      "45       1         5        False 2023-11-28 14:00:00.001     14        0\n",
      "46       1         5        False 2023-11-28 05:00:00.001      5        0\n",
      "47       1         5        False 2023-11-27 22:02:00.001     22        2\n",
      "48       1         5        False 2023-11-27 14:00:00.001     14        0\n",
      "49       1         5        False 2023-11-27 05:00:00.001      5        0\n",
      "50       2         0        False 2023-12-02 18:00:00.001     18        0\n",
      "51       2         0        False 2023-12-02 07:08:00.001      7        8\n",
      "52       2         0        False 2023-12-01 18:00:00.001     18        0\n",
      "53       2         0        False 2023-12-01 07:06:00.001      7        6\n",
      "54       2         0        False 2023-11-30 18:00:00.001     18        0\n",
      "55       2         0        False 2023-11-30 07:02:00.001      7        2\n",
      "56       2         0        False 2023-11-29 18:00:00.001     18        0\n",
      "57       2         0        False 2023-11-29 07:00:00.001      7        0\n",
      "58       2         0        False 2023-11-28 18:00:00.001     18        0\n",
      "59       2         0        False 2023-11-28 07:01:00.001      7        1\n"
     ]
    }
   ],
   "source": [
    "# Function to extract hours and minutes from timestamp\n",
    "def extract_hours_minutes(df):\n",
    "    df['hours'] = df['timestamp'].dt.hour\n",
    "    df['minutes'] = df['timestamp'].dt.minute\n",
    "    return df\n",
    "\n",
    "# Select the latest 10 records for each unique combination of 'userID' and 'deviceID' where 'eventStatus' is True\n",
    "df_true_selected_latest_10 = (\n",
    "    df_true_selected\n",
    "    .groupby(['userID', 'deviceID'])\n",
    "    .apply(lambda x: x.head(10) if len(x) >= 10 else x.tail(len(x)))\n",
    "    .pipe(extract_hours_minutes)  # Extract hours and minutes\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Select the latest 10 records for each unique combination of 'userID' and 'deviceID' where 'eventStatus' is False\n",
    "df_false_selected_latest_10 = (\n",
    "    df_false_selected\n",
    "    .groupby(['userID', 'deviceID'])\n",
    "    .apply(lambda x: x.head(10) if len(x) >= 10 else x.tail(len(x)))\n",
    "    .pipe(extract_hours_minutes)  # Extract hours and minutes\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Latest 10 True Records (Selected Columns - Sorted by Timestamp - with Hours and Minutes):\")\n",
    "print(df_true_selected_latest_10)\n",
    "\n",
    "print(\"\\nLatest 10 False Records (Selected Columns - Sorted by Timestamp - with Hours and Minutes):\")\n",
    "print(df_false_selected_latest_10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.5333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.36      0.42        14\n",
      "        True       0.55      0.69      0.61        16\n",
      "\n",
      "    accuracy                           0.53        30\n",
      "   macro avg       0.53      0.52      0.51        30\n",
      "weighted avg       0.53      0.53      0.52        30\n",
      "\n",
      "\n",
      "Support Vector Machine (SVM):\n",
      "Accuracy: 0.6333333333333333\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.21      0.35        14\n",
      "        True       0.59      1.00      0.74        16\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.80      0.61      0.55        30\n",
      "weighted avg       0.78      0.63      0.56        30\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.9666666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      1.00      0.97        14\n",
      "        True       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# from sklearn.externals import joblib  # Use joblib for saving models\n",
    "\n",
    "# Concatenate the 'Latest 10 True Records' and 'Latest 10 False Records' DataFrames\n",
    "df_combined = pd.concat([df_true_selected_latest_10, df_false_selected_latest_10], ignore_index=True)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df_combined[['userID', 'deviceID', 'hours', 'minutes']]\n",
    "y = df_combined['eventStatus']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Standardize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(X_train_scaled, y_train)\n",
    "y_pred_logreg = logreg_model.predict(X_test_scaled)\n",
    "\n",
    "# Save Logistic Regression model to a .joblib file\n",
    "joblib.dump(logreg_model, 'logreg_model.joblib')\n",
    "\n",
    "# SVM\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# Save SVM model to a .joblib file\n",
    "joblib.dump(svm_model, 'svm_model.joblib')\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Save Random Forest model to a .joblib file\n",
    "joblib.dump(rf_model, 'rf_model.joblib')\n",
    "\n",
    "# Evaluate the models\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "print(\"\\nSupport Vector Machine (SVM):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import joblib\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# # from sklearn.externals import joblib  # Use joblib for saving models\n",
    "\n",
    "# # Concatenate the 'Latest 10 True Records' and 'Latest 10 False Records' DataFrames\n",
    "# df_combined = pd.concat([df_true_selected_latest_10, df_false_selected_latest_10], ignore_index=True)\n",
    "\n",
    "# # Separate features (X) and target variable (y)\n",
    "# X = df_combined[['userID', 'deviceID', 'hours', 'minutes']]\n",
    "# y = df_combined['eventStatus']\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# # Standardize the features using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# # Logistic Regression\n",
    "# logreg_model = LogisticRegression(random_state=42)\n",
    "# logreg_model.fit(X_train_scaled, y_train)\n",
    "# y_pred_logreg = logreg_model.predict(X_test_scaled)\n",
    "\n",
    "# # Save Logistic Regression model to a .joblib file\n",
    "# joblib.dump(logreg_model, 'logreg_model.joblib')\n",
    "\n",
    "# # SVM\n",
    "# svm_model = SVC(random_state=42)\n",
    "# svm_model.fit(X_train_scaled, y_train)\n",
    "# y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# # Save SVM model to a .joblib file\n",
    "# joblib.dump(svm_model, 'svm_model.joblib')\n",
    "\n",
    "# # Random Forest\n",
    "# rf_model = RandomForestClassifier(random_state=42)\n",
    "# rf_model.fit(X_train_scaled, y_train)\n",
    "# y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# # Save Random Forest model to a .joblib file\n",
    "# joblib.dump(rf_model, 'rf_model.joblib')\n",
    "\n",
    "# # Evaluate the models\n",
    "# print(\"Logistic Regression:\")\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_logreg))\n",
    "\n",
    "# print(\"\\nSupport Vector Machine (SVM):\")\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# print(\"\\nRandom Forest:\")\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FOR TESTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logistic regression_trained_model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[374], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the saved models\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m logreg_model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogistic regression_trained_model.joblib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m svm_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvm_trained_model.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom forest_trained_model.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logistic regression_trained_model.joblib'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the saved models\n",
    "logreg_model = joblib.load('logreg_model.joblib')\n",
    "svm_model = joblib.load('svm_model.joblib')\n",
    "rf_model = joblib.load('rf_model.joblib')\n",
    "\n",
    "# Function to collect data, perform calculations, and make predictions\n",
    "def predict_event_status(user_id, device_id, timestamp_str):\n",
    "    # Convert the timestamp string to a pandas datetime object\n",
    "    timestamp = pd.to_datetime(timestamp_str, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Extract hour and minute from the timestamp\n",
    "    hour = timestamp.hour\n",
    "    minute = timestamp.minute\n",
    "\n",
    "    # Create a DataFrame with the collected data\n",
    "    new_data = pd.DataFrame({\n",
    "        'userID': [user_id],\n",
    "        'deviceID': [device_id],\n",
    "        'hours': [hour],\n",
    "        'minutes': [minute]\n",
    "    })\n",
    "\n",
    "    print('hours', hour, 'minutes', minute)\n",
    "\n",
    "    # Apply label encoding to 'userID' and 'deviceID'\n",
    "    label_encoder = LabelEncoder()\n",
    "    new_data['userID'] = label_encoder.fit_transform(new_data['userID'])\n",
    "    new_data['deviceID'] = label_encoder.fit_transform(new_data['deviceID'])\n",
    "\n",
    "    # Preprocess the new data\n",
    "    scaler = StandardScaler()\n",
    "    new_data_scaled = scaler.fit_transform(new_data[['userID', 'deviceID', 'hours', 'minutes']])\n",
    "\n",
    "    # Make predictions using the loaded models\n",
    "    logreg_prediction = logreg_model.predict(new_data_scaled)\n",
    "    svm_prediction = svm_model.predict(new_data_scaled)\n",
    "    rf_prediction = rf_model.predict(new_data_scaled)\n",
    "\n",
    "    # Return the predictions\n",
    "    return {\n",
    "        'Logistic Regression Prediction': logreg_prediction[0],\n",
    "        'SVM Prediction': svm_prediction[0],\n",
    "        'Random Forest Prediction': rf_prediction[0]\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "user_id = 'fat06b84-ceb1-4f65-8407-13cd12663818'\n",
    "device_id = '111j6h66-938q-278r-8e24-4t99e27q8371'\n",
    "timestamp_str = '2023-11-14T23:10:34.685496'\n",
    "\n",
    "predictions = predict_event_status(user_id, device_id, timestamp_str)\n",
    "print(predictions,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import awswrangler as wr\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "\n",
    "# wr.dynamodb.put_csv(path=\"results.csv\", table_name=\"DeviceTimeStamp-zvvc26kofnethfd47fmdbb2skm-dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
